[{"id":"1","name":"Introduction \r","content":"<h2 id=\"introduction\">Introduction</h2>\n<p>In today’s session we will run through four different labs. These labs are: </p>\n<p><strong>Lab 1: Azure Cloud Visibility:</strong> Troubleshoot basic issues impacting Azure resources and applications. </p>\n<p><strong>Lab 2: AWS Cloud Automation and Cloudwatch Metric Ingest:</strong> Detect performance issues impacting infrastructure and end user applications in AWS. </p>\n<p><strong>Lab 4: AWS Automation in EKS:</strong> Automate self-healing actions on EC2 and EKS services. </p>\n<p>?<strong>Lab 3: AWS Firehose log Integration:</strong> MISSING DESCRIPTION </p>","activityList":[]},{"id":"2","name":"Lab 1 – Azure Cloud Visibility \r","content":"<h2 id=\"lab1azurecloudvisibility\">Lab 1 – Azure Cloud Visibility</h2>\n<h3 id=\"introduction\">Introduction</h3>\n<p>In this lab we will use multiple resources including:</p>\n<ul>\n<li>AKS Cluster</li>\n<li>Azure Monitor</li>\n<li>Logs </li>\n<li>SLOs</li>\n<li>Clouds</li>\n</ul>\n<h3 id=\"creatinganotebooktoanalyzelogs\">Creating a Notebook to Analyze Logs</h3>\n<ol>\n<li><em>Open</em> the <strong>Notebooks app</strong>. We will create a notebook to <strong>analyze</strong> the following; <strong>logs coming from our Azure integration</strong>, and <strong>logs coming from our application deployed in AKS</strong>.</li>\n<li><em>Create</em> a <strong>new notebook</strong>.</li>\n</ol>\n<p><img src=\"assets/cd627fab51ed754524173018f3950af297a103ecb1d1d0d6b4e50dba9ef0f82c.png\" alt=\"picture 0\" />  </p>\n<ol start=\"3\">\n<li>In our <strong>new notebook</strong>, let's <em>add</em> a <strong>new section of DQL</strong>.</li>\n</ol>\n<p><img src=\"assets/dcb321d46d6f21be8a5c0271e4144d4a0ccbbef830f37acd1170d7ca563c453a.png\" alt=\"picture 1\" /> </p>\n<ol start=\"4\">\n<li>Inside the <strong>DQL section</strong> that we added, let’s <em>run</em> the <strong>following query</strong> that fetches all the records of azure using an azure subscription id as filter:</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">fetch</span> logs\n| <span class=\"hljs-keyword\">filter</span> azure.<span class=\"hljs-keyword\">subscription</span> == &quot;7A91E8B3-EE09-4906-91A2-F357B77A61FD&quot;\n</code></pre>\n<ol start=\"5\">\n<li>We can use this query to look at all the <strong>logs coming from our azure integration</strong>. We can also <em>add</em> <strong>filters</strong> for resource group, resource id, resource name or type. </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">fetch</span> logs\n| <span class=\"hljs-keyword\">filter</span> azure.<span class=\"hljs-keyword\">subscription</span> == &quot;7A91E8B3-EE09-4906-91A2-F357B77A61FD&quot;  <span class=\"hljs-keyword\">and</span> azure.resource.<span class=\"hljs-keyword\">group</span> == &quot;SCW-GROUP-JOEBAILEY&quot;\n</code></pre>\n<ol start=\"6\">\n<li>Try to <em>add</em> a <strong>new property to your query to filter your results</strong>.</li>\n<li>We are also monitoring logs coming from our <strong>AKS cluster</strong>. Let's <em>add</em> <strong>another DQL section</strong> to our notebook to <em>check</em> these logs with the <strong>next DQL query</strong>.</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">fetch</span> logs\n| <span class=\"hljs-keyword\">filter</span> matchesPhrase(k8s.<span class=\"hljs-keyword\">cluster</span>.name, &quot;perform&quot;) \n| sort <span class=\"hljs-type\">timestamp</span> <span class=\"hljs-keyword\">desc</span>\n</code></pre>\n<ol start=\"8\">\n<li>This query is showing <strong>logs</strong> coming from our <strong>AKS cluster</strong> with the name \"<strong>perform</strong>\". In all these logs we can find useful information about <strong>infrastructure performance</strong> or <strong>business-related</strong> information.</li>\n<li>In the <strong>AKS cluster</strong> we have a <strong>hipstershop application</strong> running. This application writes logs that <strong>contains business information</strong> like successful transactions or revenue. Let's <em>add</em> another <strong>DQL section</strong> to our notebook, and <em>run</em> the <strong>following query</strong> to see the number of succussful transactions.</li>\n</ol>\n<pre><code class=\"hljs\">fetch logs\n|<span class=\"hljs-built_in\"> filter </span>contains(content, <span class=\"hljs-string\">&quot;payment&quot;</span>) <span class=\"hljs-keyword\">and</span> k8s.namespace.name == <span class=\"hljs-string\">&quot;hipstershop&quot;</span>\n| parse content, <span class=\"hljs-string\">&quot;json:j&quot;</span>\n| fields timestamp, loglevel, content, <span class=\"hljs-attribute\">message</span>=j[message], <span class=\"hljs-attribute\">traceid</span>=j[dt.trace_id]\n| summarize <span class=\"hljs-attribute\">transactions</span>=count()\n</code></pre>\n<ol start=\"10\">\n<li>We have the information, but what about <strong>adding some style</strong> to the visualization? <em>Go to</em> the <strong>options button</strong> of our <strong>DQL section</strong> and <em>change</em> the <strong>visualization to single value</strong>.</li>\n</ol>\n<p><img src=\"assets/fb93a05319679f376c155b8d58b76c6859f436304ac3e6a31187043af3a11203.png\" alt=\"picture 2\" />  </p>\n<p><img src=\"assets/6a63b69d823ca9b377b3a35374adc04bf330899d774967df22e9c9ba51e8d69c.png\" alt=\"picture 3\" />  </p>\n<p>Better, right?</p>\n<ol start=\"11\">\n<li>Now, what about <strong>analyzing the revenue</strong> of these transactions? <em>Add</em> another <strong>DQL section</strong> to your notebook and <em>paste</em> the <strong>following DQL query</strong>.</li>\n</ol>\n<pre><code class=\"hljs\">fetch logs\n|<span class=\"hljs-built_in\"> filter </span>contains(content, <span class=\"hljs-string\">&quot;payment&quot;</span>) <span class=\"hljs-keyword\">and</span> k8s.namespace.name == <span class=\"hljs-string\">&quot;hipstershop&quot;</span>\n| parse content, <span class=\"hljs-string\">&quot;json:j&quot;</span>\n| fields timestamp, loglevel, content, <span class=\"hljs-attribute\">message</span>=j[message], <span class=\"hljs-attribute\">traceid</span>=j[dt.trace_id]\n| parse message, <span class=\"hljs-string\">&quot;LD &#x27;USD&#x27;, double:Amount &quot;</span>\n| summarize <span class=\"hljs-attribute\">total_revenue</span>=sum(Amount)\n</code></pre>\n<ol start=\"12\">\n<li>Let's reconfigure the visualization to <strong>single value</strong>. Let's also go to the bottom of the <strong>options menu</strong> and <em>select</em> the <strong>units and formats option</strong>.</li>\n</ol>\n<p><img src=\"assets/924c1cbf5c55ad9ff2c0bb39b93dba977c85d0f85e2278f032d34742dbf37264.png\" alt=\"picture 4\" />  </p>\n<ol start=\"13\">\n<li><em>Add</em> an <strong>override</strong>:</li>\n</ol>\n<p><img src=\"assets/97f500c840eed7d67fa3d7b4773af5f3a4afdef64111330e1635254742894045.png\" alt=\"picture 5\" />  </p>\n<ol start=\"14\">\n<li><em>Change</em> the <strong>unit to USD</strong>. Try <em>typing</em> <strong>USD in the search option</strong></li>\n</ol>\n<p><img src=\"assets/0972b5c23175a5448bfc44f76a5eead1c48beb7c32b1eb59d953cb37957370bc.png\" alt=\"picture 6\" />  </p>\n<p>That looks better.</p>\n<ol start=\"15\">\n<li>The idea of using notebooks is to enhance the collaboration in this kind of analysis. Let's <em>share</em> the <strong>notebook with the rest of the users</strong> in the environment. At the <strong>top of your notebook</strong>, first <em>change</em> the <strong>name</strong> of your notebook. Currently you'll see the title \"<strong>Untitled notebook</strong>\", <em>click</em> on <strong>it</strong> and <em>change</em> the <strong>name</strong> to <strong>[your-first-name]-perfom2025</strong>.</li>\n</ol>\n<p><img src=\"assets/421d8cfd4e5a1775a901f9c7350cb66c79c4ad56ace0e900614abb9a38564c35.png\" alt=\"picture 7\" />  </p>\n<ol start=\"16\">\n<li><em>Click</em> on the <strong>share button</strong></li>\n</ol>\n<p><img src=\"assets/10da6296def3c59bc9d92eb181b602af798ae7f9f5c799c5e39ce84adab85ddd.png\" alt=\"picture 8\" />  </p>\n<ol start=\"17\">\n<li>Once in <strong>the share menu</strong>, <em>click</em> on the <strong>gear icon</strong></li>\n</ol>\n<p><img src=\"assets/18977e31597a04fd82425e4a3a782b783a8844f1de4d0e71be90bbd01e154e09.png\" alt=\"picture 9\" />  </p>\n<ol start=\"18\">\n<li>Finally, <em>turn on</em> the <strong>“Visible to anyone in your environment” toggle</strong>.</li>\n</ol>\n<p><img src=\"assets/8a40eaca147eff8657deff1aea7cfcd3498d0938015e40b09a441311f77b01db.png\" alt=\"picture 10\" />  </p>\n<p><img src=\"assets/c2ed58035d278386dda1f714b175ee8223f0128e08c629fca6928df2e0fe9a45.png\" alt=\"picture 11\" />  </p>\n<p><img src=\"assets/18977e31597a04fd82425e4a3a782b783a8844f1de4d0e71be90bbd01e154e09.png\" alt=\"picture 14\" />  </p>\n<h3 id=\"slos\">SLOs</h3>\n<p>Now we will <em>create</em> <strong>Service Level Objectives</strong> (<strong>SLOs</strong>) to <em>track</em> the performance of our newly deployed <strong>Azure Cloud</strong>. <strong>Service Level Objectives</strong> will <em>ensure</em> that we are maintaining our <strong>standards</strong> and <strong>best practices</strong>.</p>\n<ol>\n<li><em>Open</em> up the <strong>Service-level Objectives</strong> (<strong>SLO</strong>) app. </li>\n<li><em>Create</em> a new <strong>SLO</strong>.</li>\n</ol>\n<p><img src=\"assets/0ae6a9a73c6ba3d309261791c098326dc5030a9b99063acc8c755423eab3d90d.png\" alt=\"picture 15\" />  </p>\n<ol start=\"3\">\n<li>While Dynatrace offers <strong>preset SLO options</strong> to help you get you started, we will be creating <strong>custom SLOs</strong>. <em>Select</em> the <strong>custom SLO</strong> option.</li>\n</ol>\n<p><img src=\"assets/9491869d2b47a780c51dfadc09c8db5833eb3f5f1c24728d08a3aa4be87c1fd6.png\" alt=\"picture 16\" />  </p>\n<ol start=\"4\">\n<li>Here we can <em>add</em> our <strong>custom DQL</strong>.</li>\n<li>For our first example, we will be <em>tracking</em> the number of <strong>Successful EventHub requests</strong>. To do this, we will need to <em>utilize</em> <strong>several metrics</strong> that come built-in with the <strong>Azure Event Hub Integration</strong>. <ul>\n<li><strong>dt.cloud.azure.event_hub.requests.successful</strong>  - <em>Tracks</em> the number of <strong>successful EventHub requests</strong></li>\n<li><strong>dt.cloud.azure.event_hub.errors.server</strong> – <em>Tracks</em> the number of <strong>EventHub server errors</strong></li>\n<li><strong>dt.cloud.azure.event_hub.errors.user</strong>  - <em>Tracks</em> the number of <strong>EventHub User errors</strong></li>\n<li><strong>dt.cloud.azure.event<em>hub.errors.quota</em>exceeded</strong> – <em>Tracks</em> the number of <strong>Quota Exceeded errors</strong></li>\n<li><strong>dt.cloud.azure.event_hub.requests.throttled</strong> – <em>Tracks</em> <strong>throttled EventHub requests</strong></li></ul></li>\n<li><em>Add</em> the <strong>following DQL</strong> to <em>build</em> your <strong>SLO</strong>: </li>\n</ol>\n<pre><code class=\"hljs\"> timeseries {Successful = <span class=\"hljs-built_in\">sum</span>(dt.cloud.azure.event_hub.requests.successful),\nServerErrors = <span class=\"hljs-built_in\">sum</span>(dt.cloud.azure.event_hub.<span class=\"hljs-built_in\">errors</span>.server),UserErrors = <span class=\"hljs-built_in\">sum</span>(dt.cloud.azure.event_hub.<span class=\"hljs-built_in\">errors</span>.user),QuotaExceededErrors = <span class=\"hljs-built_in\">sum</span>(dt.cloud.azure.event_hub.<span class=\"hljs-built_in\">errors</span>.quota_exceeded),Throttled = <span class=\"hljs-built_in\">sum</span>(dt.cloud.azure.event_hub.requests.throttled)}\n| fieldsAdd sli = (((Successful[] - ServerErrors[]- UserErrors[] - QuotaExceededErrors[] - Throttled[]) / Successful[]) * (<span class=\"hljs-number\">100</span>))\n| fieldsRemove Successful, ServerErrors, UserErrors, QuotaExceededErrors, Throttled\n</code></pre>\n<ol start=\"7\">\n<li><em>Refresh</em> the <strong>preview</strong> to ensure that the <strong>SLO</strong> is <em>reporting</em> results correctly.</li>\n</ol>\n<p><img src=\"assets/d7deda0069a386f0c9541f5ff0421061d5fdc6d0b1abd41fcd0feb83eed8678c.png\" alt=\"picture 17\" />  </p>\n<ol start=\"8\">\n<li><em>Hit</em> ‘<strong>Next</strong>’. Now, we will <em>set</em> our <strong>Target threshold</strong>, <strong>warning threshold</strong>, and <strong>evaluation period</strong>. The <strong>target value</strong> can be a standard set by <strong>your company</strong> or a standard set by <strong>the industry</strong>. We will <em>use</em> <strong>98%</strong>. <em>Toggle</em> the show <strong>warning</strong> option:</li>\n</ol>\n<p><img src=\"assets/0dfd0a02f8bf8f1ada54c1f4f4f5feeb3b84b243187ca562c6f3be5d9d928e6e.png\" alt=\"picture 18\" />  </p>\n<ol start=\"9\">\n<li><em>Set</em> the <strong>target</strong> to <strong>99%</strong>. Finally, <em>choose</em> your <strong>evaluation period</strong>. For this example, we can <em>use</em> the <strong>default</strong>, <strong>7 days</strong>.</li>\n<li><em>Hit</em> ‘<strong>Next</strong>’. <em>Give</em> your <strong>SLO</strong> a <strong>name</strong>, <strong>description</strong>, and any relevant <strong>tags</strong>, and <em>hit</em> ‘<strong>Save</strong>’. </li>\n<li>Your first <strong>SLO</strong> is now complete! We will <em>repeat</em> this process <strong>twice</strong> more. </li>\n<li>Our next <strong>SLO</strong> will <em>track</em> the number of <strong>Azure MySQL</strong> <strong>active connections</strong> versus the <strong>number of aborted connections</strong>. <em>Repeat</em> the <strong>steps</strong> from the 1st <strong>SLO</strong> but use this <strong>DQL</strong>: </li>\n</ol>\n<pre><code class=\"hljs\">timeseries { ActiveConnections = <span class=\"hljs-built_in\">sum</span>(cloud.azure.microsoft_dbformysql.flexibleservers.active_connections), AbortedConnections = <span class=\"hljs-built_in\">sum</span>(cloud.azure.microsoft_dbformysql.flexibleservers.aborted_connections) }\n| <span class=\"hljs-type\">fieldsAdd</span> sli = (((ActiveConnections[] - AbortedConnections[])/ ActiveConnections[]) * (<span class=\"hljs-number\">100</span>))\n| <span class=\"hljs-type\">fieldsRemove</span> ActiveConnections, AbortedConnections\n</code></pre>\n<ol start=\"13\">\n<li>We will <em>repeat</em> the same <strong>process</strong> for our third <strong>SLO</strong>. The last <strong>SLO</strong> will track our <strong>Azure App Service</strong> and track the % of requests that are <em>less</em> than <strong>500ms</strong>. <em>Use</em> the <strong>following</strong> <strong>DQL</strong>: </li>\n</ol>\n<pre><code class=\"hljs\">timeseries rsp_time = avg(dt.cloud.azure.app_service.response.avg), default:<span class=\"hljs-number\">0</span>\n<span class=\"hljs-pattern-match\">| fields<span class=\"hljs-constructor\">Add</span> high=i<span class=\"hljs-constructor\">CollectArray(<span class=\"hljs-params\">if</span>(<span class=\"hljs-params\">rsp_time</span>[]&gt; (1000 <span class=\"hljs-operator\">*</span> 500)</span>, rsp<span class=\"hljs-constructor\">_time</span>[]))\n| fields<span class=\"hljs-constructor\">Add</span> low=i<span class=\"hljs-constructor\">CollectArray(<span class=\"hljs-params\">if</span>(<span class=\"hljs-params\">rsp_time</span>[]&lt;= (1000 <span class=\"hljs-operator\">*</span> 500)</span>, rsp<span class=\"hljs-constructor\">_time</span>[]))\n| fields<span class=\"hljs-constructor\">Add</span> high<span class=\"hljs-constructor\">RespTimes</span>=i<span class=\"hljs-constructor\">CollectArray(<span class=\"hljs-params\">if</span>(<span class=\"hljs-params\">isNull</span>(<span class=\"hljs-params\">high</span>[])</span>,0,<span class=\"hljs-keyword\">else</span>:1))\n| fields<span class=\"hljs-constructor\">Add</span> low<span class=\"hljs-constructor\">RespTimes</span>=i<span class=\"hljs-constructor\">CollectArray(<span class=\"hljs-params\">if</span>(<span class=\"hljs-params\">isNull</span>(<span class=\"hljs-params\">low</span>[])</span>,0,<span class=\"hljs-keyword\">else</span>:1))\n| fields<span class=\"hljs-constructor\">Add</span> sli=100<span class=\"hljs-operator\">*</span>(low<span class=\"hljs-constructor\">RespTimes</span>[]<span class=\"hljs-operator\">/</span>(low<span class=\"hljs-constructor\">RespTimes</span>[]+high<span class=\"hljs-constructor\">RespTimes</span>[]))\n| fields<span class=\"hljs-constructor\">Remove</span> rsp<span class=\"hljs-constructor\">_time</span>, high, low, high<span class=\"hljs-constructor\">RespTimes</span>, low<span class=\"hljs-constructor\">RespTimes</span>\n</span></code></pre>\n<ol start=\"14\">\n<li>We now have 3 <strong>SLOs</strong> set up to <em>track</em> various performance objectives across our <strong>Azure</strong> deployment. </li>\n<li>Now, <em>add</em> your <strong>SLOs</strong> to a <strong>dashboard</strong> to <em>display</em> with other metrics!</li>\n</ol>\n<p><img src=\"assets/86011d72f2ab316f39143821e1bedf0a2a2425433a037beb945d6d14a1e97c5b.png\" alt=\"picture 19\" />  </p>\n<h3 id=\"lab1conclusion\">Lab 1 Conclusion</h3>\n<p>In this <strong>lab</strong> we have successfully <em>created</em> a <strong>notebook</strong> to <em>analyze</em> <strong>logs</strong> and then <strong>SLOs</strong> to <em>track</em> our <strong>Azure</strong> deployment performance.</p>","activityList":[]},{"id":"3","name":"Lab 2: AWS Cloud Visibility \r","content":"<h2 id=\"lab2awscloudvisibility\">Lab 2: AWS Cloud Visibility</h2>\n<h3 id=\"introduction\">Introduction</h3>\n<p>For intelligent <strong>monitoring</strong> of <strong>services</strong> and <strong>infrastructure</strong> running in <strong>Amazon Cloud</strong>, you can integrate Dynatrace with <strong>Amazon Web Services</strong> (<strong>AWS</strong>). The <strong>AWS Cloudwatch integration</strong>, combined with the <strong>OneAgent</strong>, helps you <strong>stay on top of the dynamics</strong> of your <strong>data center</strong> in the <strong>cloud</strong>. \nIn this lab we will complete the following objectives:</p>\n<ul>\n<li><em>Learn</em> how to <strong>configure</strong> <strong>Dynatrace</strong> to <strong>integrate with</strong> <strong>AWS</strong> <strong>CloudWatch</strong></li>\n<li><em>Learn</em> how <strong>AWS CloudWatch</strong> <strong>metrics</strong> can be configured as <strong>metric events</strong> for <strong>anomaly detection</strong> and <strong>automation</strong></li>\n<li><em>Review</em> how <strong>Dynatrace</strong> can perform <strong>self-healing</strong> tasks with a connection to <strong>AWS</strong> in <strong>workflows</strong></li>\n</ul>\n<h3 id=\"labsetup\">Lab Setup</h3>\n<p>For this lab you are going to set up an <strong>EC2 instance</strong> that runs a <strong>sample application</strong> that you can use to learn the <strong>Dynatrace</strong> <strong>platform</strong> and to review how Dynatrace brings <strong>tremendous insights</strong> all through the <strong>Dynatrace OneAgent</strong>.</p>\n<h3 id=\"dynatraceapitoken\">Dynatrace API Token</h3>\n<ol>\n<li><em>Open</em> your <strong>Dynatrace tenant</strong> and <em>navigate</em> to <strong>dashboards</strong>.</li>\n<li><em>Open</em> the <strong>Dashboard</strong> titled “<strong>APItokenDashboard</strong>”. This <em>contains</em> your <strong>API token</strong>, with all required <strong>permissions</strong>. <em>Copy</em> this <strong>value</strong> and <em>save</em> it for later.</li>\n</ol>\n<h3 id=\"awsclilabsetup\">AWS CLI Lab Setup</h3>\n<ol>\n<li><em>Open</em> up <strong>CloudShell</strong>. </li>\n</ol>\n<p>In this lab, we will be using <strong>AWS CloudShell</strong>. <strong>CloudShell</strong> is a <strong>browser-based shell</strong> that makes it <strong>easy to securely</strong> <strong>manage</strong>, <strong>explore</strong>, and <strong>interact</strong> with your <strong>AWS resources</strong>.</p>\n<p>To <em>open</em> the <strong>CloudShell</strong>, <em>click</em> on the <strong>CloudShell</strong> icon at the top of the <strong>AWS console</strong>. This may take a <em>minute</em> to <em>complete</em>.</p>\n<p><img src=\"assets/60ab8a246332230a35f52535bf621f7d10f7a6e02134476a4872fe95a7b16e05.png\" alt=\"picture 0\" />  </p>\n<p><strong><em>This may open up a slash page.</em></strong></p>\n<p><img src=\"assets/044bdf0820944ef9dce64832f5d3ea90a547c4ab155bf92970357b64bf57c91e.png\" alt=\"picture 1\" />  </p>\n<ol start=\"2\">\n<li>After <em>closing</em> the <strong>pop-up</strong>, <em>wait</em> a minute for the <strong>CloudShell</strong> <strong>to initialize.</strong> When this is done, you will see the <strong>command prompt</strong> as shown below.</li>\n</ol>\n<p><img src=\"assets/2ba73b494c29b4692669bfce380db19bd87f9d4aa7b614b3a6ddd55cac9f1eb8.png\" alt=\"picture 2\" />  </p>\n<ol start=\"3\">\n<li><em>Clone</em> the <strong>workshop scripts</strong>.</li>\n</ol>\n<p>Once you have the <strong>CloudShell</strong> open, you need to get some <strong>scripts</strong> that will <strong>automate the</strong> <strong>workshop</strong> setup. <em>Run</em> this <strong>command</strong>:</p>\n<pre><code class=\"hljs\">git clone https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/Epeiswerth/</span>aws-modernization-dt-orders-setup-saas.git\n</code></pre>\n<p>It should look like this:</p>\n<pre><code class=\"hljs\">[CloudShell-user@ip-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">52</span>-<span class=\"hljs-number\">50</span> ~]$ git clone http<span class=\"hljs-variable\">s:</span>//github.<span class=\"hljs-keyword\">com</span>/Epeiswerth/aws-modernization-dt-orders-setup-saas.git\n\nCloning into ‘aws-modernization-dt-orders-setup’…\n\nremote: Enumerating object<span class=\"hljs-variable\">s:</span> <span class=\"hljs-number\">161</span>, done.\nRemote: Counting object<span class=\"hljs-variable\">s:</span> <span class=\"hljs-number\">100</span>% (<span class=\"hljs-number\">161</span>/<span class=\"hljs-number\">161</span>), done.\nRemote: Compressing object<span class=\"hljs-variable\">s:</span> <span class=\"hljs-number\">100</span>% (<span class=\"hljs-number\">96</span>/<span class=\"hljs-number\">96</span>), done.\nRemote: Total <span class=\"hljs-number\">161</span> (delta <span class=\"hljs-number\">72</span>), reused <span class=\"hljs-number\">143</span> (delta <span class=\"hljs-number\">60</span>), pack-reused <span class=\"hljs-number\">0</span>\nReceiving object<span class=\"hljs-variable\">s:</span> <span class=\"hljs-number\">100</span>% (<span class=\"hljs-number\">161</span>/<span class=\"hljs-number\">161</span>), <span class=\"hljs-number\">19.82</span> MiB | <span class=\"hljs-number\">22.21</span> MiB/s, done.\nResolving delta<span class=\"hljs-variable\">s:</span> <span class=\"hljs-number\">100</span>% (<span class=\"hljs-number\">72</span>/<span class=\"hljs-number\">72</span>), done.\n</code></pre>\n<h3 id=\"precisionvm\">Precision VM</h3>\n<p>This step creates <strong>two</strong> <strong>CloudFormation</strong> <strong>stacks</strong> that do the following:</p>\n<ul>\n<li><em>Add</em> <strong>two</strong> <strong>EC2 instance</strong> named: <strong>dt-orders-monolith</strong> and <strong>dt-orders-services</strong></li>\n<li>At EC2 startup, it <em>installs</em> <strong>Docker</strong> and <strong>Docker-Compose</strong></li>\n<li>At EC2 startup, it <em>installs</em> the <strong>OneAgent</strong> for your <strong>Dynatrace</strong> tenant</li>\n<li>Starts up the sample <strong>application</strong> by <em>running</em> <strong>docker-compose up</strong></li>\n</ul>\n<ol>\n<li><em>Type</em>:</li>\n</ol>\n<pre><code class=\"hljs\"> <span class=\"hljs-built_in\">pwd</span>\n</code></pre>\n<p>You <em>should</em> be in the <strong>directory</strong>:</p>\n<pre><code class=\"hljs\"> <span class=\"hljs-regexp\">/home/</span>CloudShell-user\n</code></pre>\n<ol start=\"2\">\n<li><em>Copy</em> and <em>run</em> provisioning <strong>script</strong> <strong>command</strong> <em>exactly</em> as described below from the directory <strong>/home/CloudShell-user</strong></li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">cd</span> ~/aws-modernization-dt-orders-setup-saas/provision-scripts &amp;&amp; ./provision-workshop.<span class=\"hljs-keyword\">sh</span> http<span class=\"hljs-variable\">s:</span>//<span class=\"hljs-symbol\">&lt;tenantID&gt;</span>.live.dynatrace.<span class=\"hljs-keyword\">com</span> <span class=\"hljs-symbol\">&lt;API_Token&gt;</span>  &lt;Your email used <span class=\"hljs-keyword\">to</span> login <span class=\"hljs-keyword\">to</span> Dynatrace&gt;\n</code></pre>\n<p>Within the <strong>AWS SSH shell</strong>, <em>paste</em> the full <strong>command</strong> and you should see a <strong>prompt to proceed</strong> as shown below.</p>\n<pre><code class=\"hljs\">About <span class=\"hljs-keyword\">to</span> Provision Workshop <span class=\"hljs-keyword\">for</span>:\nhttp<span class=\"hljs-variable\">s:</span>//<span class=\"hljs-symbol\">&lt;tenantID&gt;</span>.live.dynatrace.<span class=\"hljs-keyword\">com</span>\nSETUP_TYPE   = <span class=\"hljs-keyword\">all</span>\nKEYPAIR_NAME = <span class=\"hljs-keyword\">ws</span>-default-keypair\nProceed? (<span class=\"hljs-keyword\">y</span>/n) : \n</code></pre>\n<p>Once the <strong>script is complete</strong>, you should <em>see</em> <strong>output</strong> as shown below.</p>\n<pre><code class=\"hljs\">Done Setting up Workshop config\n<span class=\"hljs-symbol\">End:</span> Thu Nov  <span class=\"hljs-number\">4</span> 01<span class=\"hljs-symbol\">:</span><span class=\"hljs-number\">45</span><span class=\"hljs-symbol\">:</span>06 UTC <span class=\"hljs-number\">2021</span>\nCreate AWS <span class=\"hljs-symbol\">resource:</span> monolith-vm\n{\n    “StackId”: “<span class=\"hljs-symbol\">arn:</span><span class=\"hljs-symbol\">aws:</span><span class=\"hljs-symbol\">cloudformation:</span>us-west<span class=\"hljs-number\">-2</span><span class=\"hljs-symbol\">:</span><span class=\"hljs-number\">838488672964</span><span class=\"hljs-symbol\">:stack/monolith-vm-</span><span class=\"hljs-number\">1635990306</span>/d82cd2b0<span class=\"hljs-number\">-3</span>d10<span class=\"hljs-number\">-11</span>ec-a495-023df82ab493”\n}\n</code></pre>\n<ol start=\"3\">\n<li><em>Verify</em> <strong>CloudFormation</strong> <strong>Stacks</strong></li>\n</ol>\n<p>The <strong>CloudFormation</strong> may take a few minutes, but you can <em>check</em> the <strong>CloudFormation</strong> <strong>output</strong> to ensure that all the <strong>AWS</strong> <strong>resources</strong> were provisioned successfully.</p>\n<p><em>Monitor</em> <strong>CloudFormation</strong> stack status <em>within</em> the <strong>AWS</strong> <strong>console</strong>. <em>Navigate</em> to the <strong>CloudFormation</strong> page or just navigate to:</p>\n<ul>\n<li><a href=\"https://console.aws.amazon.com/cloudformation/home\">https://console.aws.amazon.com/cloudformation/home</a></li>\n</ul>\n<p>When it is <em>complete</em>, it will show a <strong>CREATE_COMPLETE</strong> status as shown below.</p>\n<p><img src=\"assets/ac90c928218eefb1f026f237bf97ddb536378c5a6e77ae39ce4162939b01b0b7.png\" alt=\"picture 3\" />  </p>\n<h3 id=\"createanawsoidcidentityproviderforawsconnector\">Create an AWS OIDC Identity Provider for AWS Connector</h3>\n<p>The <strong>AWS Connector</strong> actions use <strong>OpenID Connect</strong> (<strong>OIDC</strong>) to authenticate with AWS, allowing them to access <strong>AWS resources</strong>. To <em>configure</em> <strong>AWS IAM</strong>, we will do the following\"</p>\n<ol>\n<li>On the left side menu, <em>Add</em> a new <strong>Identity Provider</strong>.</li>\n<li><em>Add</em> an <strong>AWS</strong> role.<ul>\n<li><em>Open</em> <strong>IAM</strong> in the <strong>AWS</strong> Console &gt; <em>Click</em> on <strong>Identity Providers</strong> &gt; <strong>Create Identity Provider</strong></li>\n<li><em>Choose</em> “<strong>OpenID Connect</strong>”</li>\n<li><em>Enter</em> in the following details</li></ul></li>\n</ol>\n<p>Provider URL: </p>\n<pre><code class=\"hljs\">https:<span class=\"hljs-regexp\">//</span>token.dynatrace.com\n</code></pre>\n<p>Audience: </p>\n<pre><code class=\"hljs\"><span class=\"hljs-symbol\">&lt;&lt;TenantID&gt;&gt;</span>.apps.dynatrace.com/app-id/dynatrace.aws.connector\n</code></pre>\n<p>It should look like this:</p>\n<p><img src=\"assets/6462762fe9c396e04fe4efb81b891bf866d29480fceb476f8e6676df20d0d5bb.png\" alt=\"picture 4\" />  </p>\n<ol start=\"3\">\n<li><em>Click</em> “<strong>Add Provider</strong>”</li>\n<li><em>Click</em> on the “<strong>Assign role</strong>” button in the upper right hand corner, and <em>Create</em> a <strong>new role</strong></li>\n</ol>\n<p><img src=\"assets/9b33199f8d51525b666abc5527ea9df1c67edbda1d95a39e994cac906b28c679.png\" alt=\"picture 5\" />  </p>\n<ol start=\"5\">\n<li><em>Select</em> <strong>Trusted entity</strong></li>\n<li><em>Choose</em> “<strong>Web Identity</strong>”</li>\n<li><strong>Identity Provider</strong> should be <em>set to</em> “<strong>token.dynatrace.com</strong>”</li>\n<li><em>Click</em> <strong>Next</strong></li>\n<li><em>Choose</em> these <strong>policies</strong></li>\n</ol>\n<p><code>AmazonEC2FullAcess</code></p>\n<p><code>eks-autoscaler-policy</code></p>\n<p><img src=\"assets/c0cdbc52a09327ad705388d0b5c286d4a59ce41f4bb81c6a3d74f4d8ae35c2ea.png\" alt=\"picture 6\" />  </p>\n<ol start=\"12\">\n<li><em>Click</em> <strong>Next</strong></li>\n<li><em>Give</em> the <strong>Role</strong> a <strong>Name</strong>:</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">Dynatrace-AWSConnectAdmin</span>\n</code></pre>\n<ol start=\"14\">\n<li>It should look <em>similar</em> to this </li>\n</ol>\n<p><img src=\"assets/ac666e7378248d6394626eef5f4fcea8b2f6bb878c9c400a119e9c6dda5aab5d.png\" alt=\"picture 7\" />  </p>\n<ol start=\"15\">\n<li><em>Create</em> the <strong>role</strong>, then <em>view</em> the <strong>role</strong></li>\n<li><em>Copy</em> the <strong>ARN</strong> of the <strong>role</strong>, and <em>save</em> <strong>it</strong> in a <strong>notepad</strong></li>\n</ol>\n<p><img src=\"assets/7f102074b771c01fb2504c1f4fab61129282277d15a93d9e217aa3f9f896d534.png\" alt=\"picture 8\" />  </p>\n<p>Now we need to allow your <strong>tenant</strong> to connect to <strong>endpoints</strong> in the <strong>allow-list</strong>. In the <strong>Dynatrace UI</strong>:</p>\n<ol>\n<li><em>Open</em> <strong>Settings App (New)</strong></li>\n<li><em>Select</em> <strong>Connections</strong></li>\n<li><em>Select</em> the <strong>Connector</strong> <strong>AWS</strong></li>\n<li><em>Add</em> a new <strong>Connection</strong><ul>\n<li>Name: </li></ul></li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">PerformAWSConnect</span>\n</code></pre>\n<p><strong>Role ARN</strong> – <em>Paste</em> in the <strong>ARN</strong> you just <em>saved</em> from the <strong>AWS console</strong></p>\n<ol start=\"5\">\n<li><em>Click</em> <strong>Create</strong></li>\n</ol>\n<p><img src=\"assets/55c2436de8165188a315d5c1d8baa47f3768a4df8e4a57f0d9f20b69ed843ea4.png\" alt=\"picture 9\" />  </p>\n<p>We need to <em>allow</em> your <strong>tenant</strong> to <em>connect</em> to <strong>endpoints</strong> in the <strong>allow-list</strong>.</p>\n<ol start=\"6\">\n<li><p>In the <strong>settings page</strong>, <em>select</em> “<strong>Limit outbound connections</strong>”</p></li>\n<li><p><em>Add</em> to the <strong>allow-list</strong></p></li>\n</ol>\n<pre><code class=\"hljs\">*<span class=\"hljs-selector-class\">.amazonaws</span><span class=\"hljs-selector-class\">.com</span>\n</code></pre>\n<ol start=\"8\">\n<li><em>Add</em> another <strong>allow-list</strong> endpoint</li>\n</ol>\n<pre><code class=\"hljs\">&lt;TenantId&gt;<span class=\"hljs-selector-class\">.live</span><span class=\"hljs-selector-class\">.dynatrace</span><span class=\"hljs-selector-class\">.com</span>\n</code></pre>\n<ol start=\"9\">\n<li><em>Save</em> <strong>Changes</strong></li>\n</ol>\n<p><img src=\"assets/9ce2a6113924fb7bd73882d48616c7cf9e654f9f52011e241cd90ca3bd960ff3.png\" alt=\"picture 10\" />  </p>\n<h3 id=\"componentsforlab2\">Components for Lab 2</h3>\n<p>Referring to the picture below, here are the <strong>components</strong> for lab 2.</p>\n<p><img src=\"assets/f7e41b9310564ff2fff0f27fc44111df541e9ca9c6624418161dec4d347f4077.png\" alt=\"picture 11\" />  </p>\n<h4 id=\"1sampleapplication\">1. Sample Application</h4>\n<p>A sample app representing a simple architecture of a <strong>frontend</strong> and <strong>backend</strong> implemented as <strong>Docker containers</strong> that we will review in this lab.</p>\n<h4 id=\"2dynatracemonitoring\">2. Dynatrace monitoring</h4>\n<p>Alongside an <strong>AWS cloudwatch integration</strong> (which we will revisit in a next step), the <strong>Dynatrace OneAgent</strong> has been installed by the <strong>workshop</strong> <strong>provisioning</strong> <strong>scripts</strong> onto the <strong>EC2 instance</strong> and is communicating to your Dynatrace Tenant.</p>\n<h5 id=\"technicalnote\">TECHNICAL NOTE</h5>\n<p>Learn more about the various ways the <strong>OneAgent</strong> can be installed, in the <a href=\"https://docs.dynatrace.com/docs/ingest-from\">Dynatrace documentation</a></p>\n<h4 id=\"3loadgeneratorprocess\">3. Load generator process</h4>\n<p>A JMeter process sends <strong>simulated user traffic</strong> to the <strong>sample app</strong> running within a Docker container. You will not need to interact with this container, it just runs in the background.</p>\n<h5 id=\"technicalnote-1\">TECHNICAL NOTE:</h5>\n<p>A real-world scenario would often start with the application components running on a <strong>physical</strong> or <strong>virtualized host</strong> <strong>on-prem</strong> and not “<strong>Dockerized</strong>”. To simplify the workshop, we <strong>“Dockerized”</strong> the application into a <strong>front-end</strong> and <strong>back-end</strong>. In <strong>Dynatrace</strong>, these Docker containers all show up as “<strong>processes</strong>” on a <strong>host</strong> just like a “<strong>non-Dockerized</strong>” <strong>application</strong> will.</p>\n<h4 id=\"sampleapp\">Sample app</h4>\n<p>The sample application is called <strong>Dynatrace Orders</strong>. A more <strong>detailed overview</strong> &amp; <strong>source code</strong> can be found on <a href=\"https://github.com/dt-orders/overview\">GitHub</a>. </p>\n<h4 id=\"getthepubliciptothefrontendofthesampleapplication\">Get the Public IP to the frontend of the Sample Application</h4>\n<p>To get the <strong>Public IP</strong>, <em>open</em> the <strong>EC2 instances</strong> page in the <strong>AWS console</strong>. On the newly created <strong>host</strong> <strong>dt-orders-monolith</strong> <em>find</em> the <strong>Public IP</strong> as shown below.</p>\n<p><img src=\"assets/9ef19c308bece21b0b6c0dfe116b5a72bf3b194b627e99f3aa8ba584409d0d61.png\" alt=\"picture 12\" />  </p>\n<h4 id=\"viewthesampleappinabrowser\">View the Sample app in a Browser</h4>\n<p>To view the application, <em>paste</em> the <strong>public IP</strong> using <strong>HTTP</strong>, NOT HTTPS, into a <strong>browser</strong> that will look like this:</p>\n<p><img src=\"assets/5f1105efffa42eef00af1c80c083ebbeaa2bcba8e7e509ec41e64659acdebca9.png\" alt=\"picture 13\" />  </p>\n<p><em>Use</em> the <strong>menu</strong> on the <strong>home page</strong> to <em>navigate</em> around the <strong>application</strong>. <em>Note</em> the <strong>URL</strong> for key functionality. You will see these <strong>URLs</strong> later as we <em>analyze</em> the <strong>application</strong>.</p>\n<ul>\n<li><strong>Customer List</strong> = customer/list.html</li>\n<li><strong>Customer Detail</strong> - Each customer has a unique page = customer/5.html</li>\n<li><strong>Catalog List</strong> = catalog/list.html</li>\n<li><strong>Catalog Search Form</strong> = catalog/searchForm.html</li>\n<li><strong>Order List</strong> = order/list.html</li>\n<li><strong>Order Form</strong> = order/form.html</li>\n</ul>\n<h3 id=\"oneagentdata\">OneAgent Data</h3>\n<p><em>Review</em> the <strong>Infrastructure and Operations App</strong> to <em>view</em> the <strong>Monolith VM</strong>.</p>\n<p><img src=\"assets/a18b74c0ed249e76ef6e8d84492a12a27d87731ee6cac2226e4528c791efc80b.png\" alt=\"picture 14\" />  </p>\n<p><img src=\"assets/b70b64d38ac8c1954432561682dfdafcb5bf025fd9ca3f6df4d22863602f8ed0.png\" alt=\"picture 15\" />  </p>\n<p><img src=\"assets/b2e33953dce1cf6fc34c576f031a8076ae10cd1f352208971a73245a0cbd4b44.png\" alt=\"picture 16\" />  </p>\n<p><img src=\"assets/4d8309ce41bf5ea333e96cce8a08a8fe3c8900c184f9f0f969a23e4a40009c31.png\" alt=\"picture 17\" />  </p>\n<h3 id=\"cloudsapp\">Clouds App</h3>\n<p>In addition to monitoring your <strong>AWS workloads</strong> using <strong>OneAgent</strong>, Dynatrace provides integration with <strong>AWS CloudWatch</strong> which adds <strong>infrastructure monitoring</strong> to gain insight even into all popular <strong>AWS services</strong> (e.g. serverless application scenarios).</p>\n<h4 id=\"howthishelps\">How this helps</h4>\n<p>The <strong>AWS</strong> <strong>Cloudwatch</strong> <strong>integration</strong> brings <strong>logs</strong> and additional <strong>metrics</strong> for <strong>cloud infrastructure</strong>, <strong>load balancers</strong>, <strong>API Management Services</strong>, and <strong>more</strong> into the Dynatrace platform. Dynatrace brings value by <strong>enriching the data in context</strong> with <strong>all observability signal</strong>s. </p>\n<p>The <strong>Cloudwatch metrics</strong> are managed by <strong>Dynatrace’s AI engine</strong> <strong>automatically</strong> and this extended observability <strong>improves operations</strong>, <strong>reduces MTTR</strong> and <strong>increases innovation</strong>.</p>\n<p>Here is an example, <strong>filtered</strong> for the <strong>AWS account</strong> of this lab:</p>\n<p><img src=\"assets/c6a73a459db444c7095b038d124017e9fed7103d4b9606c4115e3470174f8281.png\" alt=\"picture 18\" />  </p>\n<p>The <strong>Clouds</strong> <strong>App</strong> gives you a <strong>unified perspective</strong> among your <strong>multi-cloud inventories</strong> and allows you to drilldown to your relevant set of <strong>cloud services</strong>. For example you can filter by:</p>\n<ul>\n<li>Region</li>\n<li>Service Category (e.g. Databases)</li>\n<li>Service Type (e.g. AWS Lambda)</li>\n<li>Service Name</li>\n<li>Account ID (Environment)</li>\n<li>Tags</li>\n</ul>\n<h3 id=\"handsonexerciseawscloudwatchmetricintegration\">Hands-on Exercise – AWS Cloudwatch metric integration</h3>\n<ol>\n<li>From the <strong>Clouds App</strong> &gt; <strong>Configure</strong> &gt; <strong>AWS</strong> &gt; <strong>Connect new Instance</strong></li>\n<li><em>Add</em> the <strong>following information</strong>:</li>\n</ol>\n<ul>\n<li><strong>Connection Name</strong>: </li>\n</ul>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">Dynatrace Integration</span>\n</code></pre>\n<ul>\n<li><strong>Auth method</strong>: Role Based authentication</li>\n<li><strong>IAM Role</strong>: </li>\n</ul>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">Dynatrace_monitoring_role</span>\n</code></pre>\n<ul>\n<li>Your <strong>AWS</strong> <strong>account ID</strong>: found on the <strong>AWS console</strong> <strong>top right-hand dropdown</strong>.</li>\n<li><strong>Monitor all resources</strong></li>\n</ul>\n<p><em>Click</em> <strong>Save</strong></p>\n<p><img src=\"assets/123595159bcc266f22a4229f80f0931cc7700e0c34303c89a079a80c923af5c4.png\" alt=\"picture 19\" />  </p>\n<ol start=\"3\">\n<li>Once the <strong>connection</strong> is successfully <em>verified</em> and <em>saved</em>, your <strong>AWS account</strong> will be listed in the <strong>Clouds</strong> app:</li>\n</ol>\n<p><img src=\"assets/149909954e0f5f1f089d696fab0a65b6ae641c78a961358ebc7000fb5c4270e2.png\" alt=\"picture 20\" />  </p>\n<h4 id=\"reviewcollectedmetrics\">Review Collected Metrics</h4>\n<p>Let’s <em>navigate</em> to the <strong>AWS dashboards</strong> that were automatically created as soon as you hooked up the integration with <strong>AWS Cloudwatch</strong>:</p>\n<p><img src=\"assets/d6ab236797b7d815825456b92f956d620882ea4844d90abc71ef5afca177663f.png\" alt=\"picture 21\" />  </p>\n<h4 id=\"whyisthisimportant\">Why is this important?</h4>\n<p>The <strong>AWS monitor</strong> is a central way to get a <strong>picture</strong> and <strong>metrics</strong> for the <strong>AWS resources</strong> running against your <strong>accounts</strong> as you migrate.</p>\n<p>Read more about how to <strong>scale your</strong> <strong>enterprise cloud environment</strong> with enhanced <strong>AI-powered</strong> <strong>observability</strong> of all <strong>AWS services</strong> in this <strong>Dynatrace</strong> blog: <a href=\"https://www.dynatrace.com/news/blog/monitor-any-aws-service/\">https://www.dynatrace.com/news/blog/monitor-any-aws-service/</a>. </p>\n<h4 id=\"custommetricevents\">Custom Metric Events</h4>\n<p>Dynatrace Davis <strong>automatically analyzes</strong> abnormal situations within your <strong>IT infrastructure</strong> and attempts to <strong>identify any relevant</strong> <strong>impact</strong> and <strong>root causes</strong>. </p>\n<p>Davis relies on a wide spectrum of information sources, such as a <strong>transactional</strong> <strong>view</strong> of your <strong>services</strong> and <strong>applications</strong>, as well as <strong>all events raised</strong> on individual nodes within your <strong>Smartscape topology</strong>.</p>\n<p>There are two main <strong>sources</strong> for single events in Dynatrace:</p>\n<ol>\n<li><strong>Metric-based events</strong> (events that are triggered by a series of measurements)</li>\n<li><strong>Events</strong> that are independent of any <strong>metric</strong> (for example, <strong>process crashes</strong>, <strong>deployment changes</strong>, and <strong>VM motion events</strong>)</li>\n</ol>\n<p><strong>Custom metric events</strong> are configured in the <strong>global settings</strong> of your <strong>environment</strong>, and are <em>visible</em> to all <strong>Dynatrace</strong> users in your <strong>environment</strong>.</p>\n<h3 id=\"handsoncustomanomalydetection\">Hands-on Custom Anomaly Detection</h3>\n<p><strong>Davis Anomaly Detection</strong> allows you to create <strong>anomaly detectors</strong>, set up <strong>customized alerts</strong>, and <strong>transform</strong> <strong>metric events</strong> configuration. </p>\n<p>You can also save time and create an <strong>anomaly detector</strong> in <strong>Notebooks</strong> while using the <strong>app</strong>. We will be using the <strong>metrics</strong> <em>captured</em> from <strong>AWS</strong>.</p>\n<ol>\n<li><em>Go</em> to the app <strong>Davis Anomaly Detection</strong>.</li>\n<li><em>Select</em> the <strong>“Settings”</strong> dropdown in the upper right-hand corner, <em>select</em> <strong>Authorization Settings</strong>, and <em>select</em> <strong>All permissions</strong>.</li>\n<li><em>Select</em> <strong>Anomaly Detector</strong> &gt; <strong>Create your own Anomaly Detector</strong>.</li>\n<li><em>Give</em> your configuration a meaningful <strong>Title</strong>, like: </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">High</span> EC<span class=\"hljs-number\">2</span> CPU Usage %\n</code></pre>\n<ol start=\"5\">\n<li><em>Configure</em> your <strong>query</strong> and <em>provide</em> the <strong>DQL query</strong> to <em>fetch</em> your <strong>data</strong>.</li>\n<li><strong>DQL Query</strong>: </li>\n</ol>\n<pre><code class=\"hljs\">timeseries max(dt.host.cpu.usage), <span class=\"hljs-built_in\">by</span>: {dt.entity.ec2_instance, dt.source_entity}\n| <span class=\"hljs-type\">lookup</span> [fetch `dt.entity.EC2_INSTANCE`\n  | <span class=\"hljs-type\">fields</span> id, entity.name, tags, awsInstanceId], sourceField:dt.entity.ec2_instance, lookupField:id\n| <span class=\"hljs-type\">fieldsAdd</span> EC2Tags = lookup.tags, awsInstanceId = lookup.awsInstanceId\n| <span class=\"hljs-type\">expand</span> EC2Tags\n| <span class=\"hljs-type\">filter</span> EC2Tags == <span class=\"hljs-string\">&quot;[AWS]Name:dt-orders-monolith&quot;</span>\n</code></pre>\n<ol start=\"7\">\n<li><strong>Actor</strong>: Yourself</li>\n</ol>\n<h5 id=\"customizeparameters\">Customize Parameters</h5>\n<ol>\n<li><strong>Analyzers:</strong> Static threshold anomaly detection</li>\n<li><strong>Threshold</strong>: 70</li>\n<li><em>Click</em> on “<strong>Show Advanced Properties</strong>”. <em>Change</em> the <strong>values</strong> to:<ul>\n<li><strong>Violating Samples</strong>: 1  </li>\n<li><strong>Sliding Window</strong>: 3 </li>\n<li><strong>Dealerting samples</strong>: 3</li></ul></li>\n</ol>\n<p><img src=\"assets/db270a83c38436b483edf9026828fa94d243787bd33ccfa6e6dfeb5a2af7feee.png\" alt=\"picture 22\" />  </p>\n<ol start=\"4\">\n<li><strong>Alert condition</strong>: Alert if Metric is Above</li>\n<li><em>Create</em> an <strong>Event Template</strong></li>\n</ol>\n<ul>\n<li><strong>Event Name</strong>: </li>\n</ul>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">High</span> EC<span class=\"hljs-number\">2</span> CPU Usage %\n</code></pre>\n<ul>\n<li>Event Description: </li>\n</ul>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">The</span> {metricname} <span class=\"hljs-keyword\">on</span> {dims:dt.source_entity} <span class=\"hljs-keyword\">exceeded</span> {threshold} <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">AWS</span> <span class=\"hljs-keyword\">tags</span> {dims:EC2Tags}\n</code></pre>\n<ul>\n<li><em>Configure</em> your <strong>Event Properties</strong> to look like this</li>\n</ul>\n<p><img src=\"assets/36767a1322ce80cab613a793b19f0d74692bebb6efd5253c05c9b7437c71e4ed.png\" alt=\"picture 23\" />  </p>\n<ol start=\"9\">\n<li><em>Click</em> <strong>Create</strong>.</li>\n</ol>\n<h3 id=\"awsconnectforworkflows\">AWS Connect for Workflows</h3>\n<p><em>Open</em> the <strong>AWS CLI</strong>.</p>\n<h4 id=\"triggerworkflowwithproblemcard\">Trigger Workflow with Problem Card</h4>\n<p>We are going to create a <strong>self-healing</strong> <strong>workflow</strong> that gets triggered from the <strong>anomaly detection</strong> <strong>event</strong> you just created for the <strong>EC2</strong> <strong>CPU usage</strong>. </p>\n<p>This workflow will take advantage of the <strong>AWS Connector integration</strong>. <strong>AWS Connector</strong> enables your Dynatrace environment to interact with different <strong>AWS Services</strong> based on <strong>events</strong> and <strong>schedules</strong> defined in a dedicated <strong>workflow</strong>.</p>\n<p>In a <strong>workflow</strong>, you can <strong>query</strong> and <em>manipulate</em> <strong>AWS</strong> resources, such as <strong>EC2 instances</strong> or <strong>S3 buckets</strong>. </p>\n<p><strong>AWS Connector</strong> provides an extensive set of <strong>workflows</strong> actions, which <em>offer</em> a familiar interface very closely aligned with <strong>AWS CLI</strong> so that you can use <em>actions</em> and <em>concepts</em> that are already well known to you.</p>\n<h4 id=\"createec2rebootworkflow\">Create EC2 Reboot workflow</h4>\n<ol>\n<li>To authorize the service account running this workflow, in the <strong>upper right hand corner</strong>, <em>click</em> on “<strong>Settings</strong>” then <em>select</em> “<strong>Authorization settings</strong>”</li>\n</ol>\n<p><img src=\"assets/5a15d7d47ca2a6886e28364649885a7af29f6b3e032f83356e91c8028eb67966.png\" alt=\"picture 24\" />  </p>\n<ol start=\"2\">\n<li><em>Grant</em> <strong>all</strong> <strong>Permissions</strong> and <em>Close</em> the <strong>popup window</strong>. The below message indicates that there are <strong>some</strong> <strong>permissions</strong> that could not be granted to the <strong>workflow service account</strong> because the group you are a part of does not have them granted in the <strong>policy</strong>. They are not needed for this lab.</li>\n</ol>\n<p><img src=\"assets/f70ef9caaac48cd85e0bc3adae57af6a0822dac40407ad7186b0a5daea687876.png\" alt=\"picture 25\" />  </p>\n<ol start=\"3\">\n<li><em>Click</em> on the <strong>Workflows App</strong> &gt; <em>click</em> on “<strong>+Workflow</strong>”</li>\n<li><em>Select</em> Trigger: <strong>On demand trigger</strong></li>\n<li><em>Click</em> on add <strong>task</strong> right below trigger box</li>\n<li><em>Search</em> for <strong>actions</strong>, and <em>select</em>: </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-symbol\">EC2:</span> Describe instances\n</code></pre>\n<ol start=\"7\">\n<li>In the <strong>Connection</strong> space, <em>find</em> the <strong>Connection</strong> you just <em>built</em> “<strong>PerformAWSConnect</strong>”</li>\n<li>In the <strong>region</strong> section, <em>click</em> on the code box “<strong>Add Expression</strong>” on the right hand side of the region field. <em>Delete</em> all the curly brackets and type: </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">us</span>-west-<span class=\"hljs-number\">2</span>\n</code></pre>\n<ol start=\"9\">\n<li>In <strong>Filters</strong> <em>enter</em> the following</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">ta</span><span class=\"hljs-variable\">g:Name</span>\n</code></pre>\n<pre><code class=\"hljs\"><span class=\"hljs-selector-tag\">dt</span>-orders-monolith\n</code></pre>\n<ol start=\"10\">\n<li><em>Click</em> <strong>Save</strong>, then <strong>Run</strong></li>\n<li>Once it runs successfully, <em>click</em> on the <strong>action</strong> in the <strong>workflow</strong> and it should show the result as shown below. You can <em>expand</em> the result to see the list of <strong>VM instances</strong> and their <strong>IDs</strong>. We will <em>parse</em> this result to pull out the <strong>instance ID</strong> for the next step.</li>\n</ol>\n<p><img src=\"assets/5e1cb0ec181088fde94fead1b8b5e6d65d7ef6d320d3aa1754b5d97e1f436e61.png\" alt=\"picture 26\" />  </p>\n<ol start=\"12\">\n<li><em>Add</em> another task, “<strong>EC2 Reboot Instances</strong>”</li>\n<li>In the <strong>region section</strong>, <em>click</em> on the code box “<strong>Add Expression</strong>” on the right hand side of the region field. <em>Delete</em> all the curly brackets and type: </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">us</span>-west-<span class=\"hljs-number\">2</span>\n</code></pre>\n<ol start=\"14\">\n<li><em>Add</em> this <strong>parameter</strong> in the “<strong>instanceIds</strong>” field, and <em>Save</em> the <strong>Workflow</strong></li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-template-variable\">{{<span class=\"hljs-name\">result</span>(<span class=\"hljs-name\">&quot;ec2_describe_instances_1&quot;</span>).Reservations[0].Instances[0].InstanceId}}</span><span class=\"xml\">\n</span></code></pre>\n<p><img src=\"assets/b39a63ba1f98dc8bdc150a93b1e69bfb697a23b58830c19f8bb6eea5a6e94c1a.png\" alt=\"picture 27\" />  </p>\n<ol start=\"15\">\n<li><em>Change</em> the <strong>trigger</strong> type to “<strong>Davis problem trigger</strong>”</li>\n<li><em>Describe</em> the <strong>trigger</strong> as seen below to recognize the <strong>custom event</strong> type from your <strong>anomaly detection rule</strong>.</li>\n</ol>\n<p><img src=\"assets/db3ddc56740ab0ab30a5b1849e8052883c7d35ca9eb8245c0e2f801a35b7be90.png\" alt=\"picture 28\" />  </p>\n<ol start=\"17\">\n<li><em>Filter</em> on <strong>tags</strong> with the <strong>key:value pair</strong>:</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-string\"> [AWS]</span>Name\n</code></pre>\n<pre><code class=\"hljs\"> <span class=\"hljs-selector-tag\">dt</span>-orders-monolith\n</code></pre>\n<ol start=\"18\">\n<li><em>Save</em> the <strong>Workflow</strong></li>\n<li><em>Change</em> the name of the <strong>workflow</strong> to “<strong>Reboot Monolith VM</strong>” by <em>clicking</em> on the <strong>title</strong>. Then <em>Save</em> the <strong>Workflow</strong> again.</li>\n</ol>\n<h4 id=\"triggercustomproblemalerts\">Trigger Custom Problem Alerts</h4>\n<h5 id=\"sshtomonolithhost\">SSH to monolith host</h5>\n<p>We are going to manually trigger a <strong>CPU problem</strong> on the <strong>monolith VM</strong>. This will <strong>generate a problem</strong> from your <strong>custom anomaly detection rule</strong> and will trigger the <strong>EC2 reboot workflow</strong>. </p>\n<p>To connect to the host, simply use <strong>EC2 Instance Connect</strong>. To do this, <em>navigate</em> to the <strong>EC2 instances</strong> page in the <strong>AWS console</strong>.</p>\n<p>From the list, <em>pick</em> the <strong>dt-orders-monolith</strong> (1) and then the <strong>Connect button</strong> (2) as shown below.</p>\n<p><img src=\"assets/0eeb0389b9ae9ce9d1d69c8ada750992629bd494a0f236268da28af4cb1bc6a6.png\" alt=\"picture 29\" />  </p>\n<p>Then on the next page, <em>choose</em> the <strong>EC2 Instance Connect</strong> option and then the <strong>connect button</strong>.</p>\n<p><img src=\"assets/ff824d32093238757b6dd9ec9b5997f2d6a6c77fc071e4105ca1774c2174d9cf.png\" alt=\"picture 30\" />  </p>\n<p>Once you're connected, you will see the terminal prompt like below.</p>\n<pre><code class=\"hljs\">Welcome <span class=\"hljs-keyword\">to</span> Ubuntu <span class=\"hljs-number\">20.04</span><span class=\"hljs-number\">.2</span> LTS (GNU/Linux <span class=\"hljs-number\">5.4</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">-1045</span>-aws x86_64)\n...\n...\n<span class=\"hljs-keyword\">To</span> <span class=\"hljs-built_in\">run</span> a command as administrator (user <span class=\"hljs-string\">&quot;root&quot;</span>), use <span class=\"hljs-string\">&quot;sudo &lt;command&gt;&quot;</span>.\nSee <span class=\"hljs-string\">&quot;man sudo_root&quot;</span> <span class=\"hljs-keyword\">for</span> details.\nubuntu<span class=\"hljs-symbol\">@ip</span><span class=\"hljs-number\">-10</span><span class=\"hljs-number\">-0</span><span class=\"hljs-number\">-0</span><span class=\"hljs-number\">-118</span>:~$ \n</code></pre>\n<ol>\n<li><em>Trigger</em> a <strong>CPU problem</strong></li>\n<li>\nUsing a <strong>unix utility yes</strong>, we can generate <strong>CPU stress</strong> just by <em>running</em> the <strong>yes command</strong> a few times.\nIn the terminal, <em>copy</em> <strong>all these lines</strong> and <em>run</em> <strong>them</strong>:</li>\n</ol>\n<pre><code class=\"hljs\">yes &gt; <span class=\"hljs-regexp\">/dev/</span><span class=\"hljs-literal\">null</span> &amp;\nyes &gt; <span class=\"hljs-regexp\">/dev/</span><span class=\"hljs-literal\">null</span> &amp;\nyes &gt; <span class=\"hljs-regexp\">/dev/</span><span class=\"hljs-literal\">null</span> &amp;\n</code></pre>\n<p>To verify, <em>run</em> this <strong>command</strong>:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">ps</span> -ef | grep <span class=\"hljs-literal\">yes</span>\n</code></pre>\n<p>The output should look like this:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5802</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">99</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span> yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5805</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">89</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">04</span> yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5806</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">97</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">03</span> yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5818</span>  <span class=\"hljs-number\">5438</span>  <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> grep --color=auto yes\n</code></pre>\n<ol start=\"3\">\n<li>Back in Dynatrace within the <strong>Infrastructure and Operations view</strong>, the CPU should now be high, as shown below:</li>\n</ol>\n<p><img src=\"assets/889db60334e2f0cbac868cd6e79a0589d5fd82b57624551499848efb97ebfd6e.png\" alt=\"picture 31\" />  </p>\n<ol start=\"4\">\n<li>It may take a minute or so, but you will get a <strong>problem card</strong> shown below. #1 is the alert from the <strong>severity = RESOURCE</strong> where Davis AI was invoked, and #2 is the alert from <strong>severity = CUSTOM ALERT</strong>.</li>\n</ol>\n<p><img src=\"assets/948c733b39c7f6a7c2108a2068a751544d9a54b1d836b161090d2d2c950faa7c.png\" alt=\"picture 32\" />  </p>\n<ol start=\"5\">\n<li><em>Navigate</em> back to the <strong>Workflows App</strong> and find the <strong>workflow you just created</strong></li>\n<li><em>Click</em> on the <strong>ellipsis button</strong> to view the execution history</li>\n</ol>\n<p><img src=\"assets/cdbfadd48347e2fcd83f5ac2c57fd6a21a46e7f0d221039339e8342f8b49bc87.png\" alt=\"picture 33\" />  </p>\n<ol start=\"7\">\n<li>It should show a successful run that was triggered by the Davis AI detected <strong>custom alert problem</strong>:</li>\n</ol>\n<p><img src=\"assets/c1efee416d2c15bf5db3baa2f04bdbb6135bc4568c5564bd53c7bb63f61068fc.png\" alt=\"picture 34\" />  </p>\n<h5 id=\"optionaliftheworkflowdoesnotcorrectlyrebootyourvm\"><em>(Optional – If the workflow does not correctly reboot your VM)</em></h5>\n<p>To stop the problem, you need to <em>kill</em> the <strong>processes</strong>. To do this:</p>\n<ol>\n<li>Back in <strong>CloudShell</strong>, <em>run</em> this <strong>command</strong> to get the <strong>process IDs</strong> </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">ps</span> -ef | grep <span class=\"hljs-literal\">yes</span> \n</code></pre>\n<ol start=\"2\">\n<li>For each <strong>process</strong>, <em>copy</em> the <strong>process ID</strong> and <em>run</em> <strong>kill</strong> &lt;PID></li>\n</ol>\n<p>For example:</p>\n<h5 id=\"iftheoutputisthis\">If the output is this…</h5>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">ubuntu</span>@ip-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">118</span>:~$ ps -ef | grep yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5802</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">99</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span> yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5805</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">89</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">04</span> yes\n<span class=\"hljs-attribute\">ubuntu</span>    <span class=\"hljs-number\">5806</span>  <span class=\"hljs-number\">5438</span> <span class=\"hljs-number\">97</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">48</span> pts/<span class=\"hljs-number\">0</span>    <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">03</span> yes\n</code></pre>\n<h5 id=\"thenrun\">Then run…</h5>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">kill</span> <span class=\"hljs-number\">5802</span>\n<span class=\"hljs-attribute\">kill</span> <span class=\"hljs-number\">5805</span>\n<span class=\"hljs-attribute\">kill</span> <span class=\"hljs-number\">5806</span>\n</code></pre>\n<p>Or better to use the below <strong>command</strong> to <em>kill</em> all the <strong>PID’s</strong> at once</p>\n<pre><code class=\"hljs\">kill <span class=\"hljs-constructor\">$(<span class=\"hljs-params\">ps</span> -<span class=\"hljs-params\">ef</span> | <span class=\"hljs-params\">grep</span> <span class=\"hljs-params\">yes</span> | <span class=\"hljs-params\">awk</span> &#x27;{<span class=\"hljs-params\">print</span> $2}&#x27; | <span class=\"hljs-params\">sed</span> &#x27;$<span class=\"hljs-params\">d</span>&#x27;)</span>\n</code></pre>\n<p>Or even more effective is:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">pkill</span> <span class=\"hljs-literal\">yes</span>\n</code></pre>\n<ol start=\"3\">\n<li><em>Verify</em> they are gone by <em>running</em> this again: </li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">ps</span> -ef | grep <span class=\"hljs-literal\">yes</span>\n</code></pre>\n<ol start=\"4\">\n<li><em>Verify</em> that <strong>CPU</strong> in Dynatrace goes to normal and the <strong>problems</strong> will eventually <em>automatically</em> close.</li>\n<li><em>Exit</em> the <strong>SSH</strong>: Simply type <strong>“exit”</strong> to return to the <strong>CloudShell</strong>.</li>\n</ol>\n<h3 id=\"lab2conclusion\">Lab 2 Conclusion</h3>\n<p>In this section, you have completed the following:</p>\n<ul>\n<li>Review how Dynatrace integrates with <strong>AWS CloudWatch</strong></li>\n<li>Review how <strong>Infrastructure metrics</strong> can be configured as <strong>Metric events</strong> for alerts</li>\n<li>Review how Dynatrace can perform <strong>self-healing</strong> tasks with a connection to <strong>AWS</strong> in <strong>workflows</strong></li>\n</ul>","activityList":[]},{"id":"4","name":"Lab 4 – Kubernetes Observability and EKS Autoscaling Workflow \r","content":"<h2 id=\"lab4kubernetesobservabilityandeksautoscalingworkflow\">Lab 4 – Kubernetes Observability and EKS Autoscaling Workflow</h2>\n<h3 id=\"introduction\">Introduction</h3>\n<p>In this lab, we will learn how to observe and <strong>troubleshoot Kubernetes clusters</strong> with Dynatrace. We will use the <strong>out-of-the-box health assessment</strong> provided by Dynatrace to detect and analyze a reliability issue. Additionally, we will build a workflow to <strong>automate a self-healing action</strong> for this use case.  </p>\n<p>For the hands-on part of this lab, we will showcase the integration with <strong>AWS EKS</strong> via Dynatrace Operator (on top of the Cloudwatch integration). We will create a workflow and you will see the workflow execution <strong>triggered by Dynatrace Davis AI</strong>. </p>\n<h3 id=\"labprerequisites\">Lab Prerequisites</h3>\n<p>The following assets / scripts have already been triggered in Lab 2: </p>\n<ul>\n<li><strong>Create CloudFormation Stacks</strong> by executing provisionWorkshop.sh script </li>\n<li><strong>Create an AWS OIDC Identity Provider</strong> for AWS Connector  </li>\n<li><strong>Allow outbound AWS Connection</strong> (“AWS Connect for Workflows”) </li>\n<li><strong>Authorization Settings in Workflow App</strong> for Service User are granted </li>\n</ul>\n<h3 id=\"labsetup\">Lab Setup</h3>\n<p>For this lab you are going to use an <strong>updated version of the order application</strong> in Kubernetes. This makes it easy for you to see the <strong>transformation of the Sample Application</strong> in Lab 2 and the value of running Kubernetes on AWS without needing to stand up or maintain your own Kubernetes control plane. </p>\n<h3 id=\"verifycloudformationstacks\">Verify CloudFormation Stacks</h3>\n<p>We have automated the EKS setup for this lab by <strong>leveraging CloudFormation stacks</strong>. As this has been already included in the initial workshop provisioning script triggered in Lab 2, we should already have an EKS cluster with 2 nodes as well as an integration with Dynatrace up and running. Please check the <strong>CloudFormation output</strong> to ensure that all the <strong>AWS resources were provisioned successfully</strong>. </p>\n<p>Monitor CloudFormation stack status within the AWS console. </p>\n<p><em>Navigate</em> to the <strong>CloudFormation page</strong> or just <em>navigate</em> to: </p>\n<ul>\n<li><a href=\"https://console.aws.amazon.com/cloudformation/home\">https://console.aws.amazon.com/cloudformation/home</a> </li>\n</ul>\n<p>When it is complete, it will show a <strong>CREATE_COMPLETE</strong> status as shown below. </p>\n<p><img src=\"assets/0ccf50643253ca9cd2730bed737464cf81e6c058be29e2fad2f96d2a75a96141.png\" alt=\"picture 0\" />  </p>\n<h3 id=\"verifyclusterwithinawsconsole\">Verify Cluster within AWS Console</h3>\n<p>With the AWS Console, <em>search</em> for the “<strong>Elastic Kubernetes Service</strong>” or <em>click</em> on the <strong>link below</strong>.</p>\n<ul>\n<li><a href=\"https://console.aws.amazon.com/eks/home#/clusters\">https://console.aws.amazon.com/eks/home#/clusters</a></li>\n</ul>\n<p>On the <strong>cluster page</strong>, <em>click</em> on cluster “<strong>dynatrace-workshop</strong>”. </p>\n<p>Next <em>click</em> on the <strong>compute</strong> tab. </p>\n<p>You will see <strong>2 Kubernetes nodes</strong> managed by one node group. </p>\n<p><em>Click</em> on the <strong>NodeGroup</strong> and <em>review</em> the <strong>details</strong>. The node group is managed by an <strong>EC2 Autoscaling group</strong> with a lower (Minimum size) and upper (Maximum size) boundary.</p>\n<p><img src=\"assets/724ad746591462dda3ab44a7ff6cb7f52c77954ae504738f544059e2b2f0f31e.png\" alt=\"picture 1\" />  </p>\n<h3 id=\"deployapponeks\">Deploy App on EKS</h3>\n<p>For this lab, another version of the application exists that breaks out each of these <strong>backend services</strong> into <strong>separate services</strong>. By putting these services into container images, we gain the ability to deploy the service into <strong>containerized workloads in EKS</strong>.</p>\n<p><img src=\"assets/fec982a5e64af73e5592aeaf0e3bab811ca1e0e70d6a8da497062f13b963b1dc.png\" alt=\"picture 2\" />  </p>\n<h3 id=\"deploysampleapponeks\">Deploy sample app on EKS</h3>\n<p><em>Copy</em> &amp; <em>paste</em> the <strong>following command</strong> in your <strong>AWS cloud shell</strong> to <em>deploy</em> the <strong>sample app</strong></p>\n<pre><code class=\"hljs\"> <span class=\"hljs-keyword\">cd</span> ~<span class=\"hljs-string\">/aws-modernization-dt-orders-setup-saas/app-scripts</span>\n<span class=\"hljs-string\">./start-k8.sh</span>\n</code></pre>\n<p>The output should look similar to this:</p>\n<p><img src=\"assets/38b65b0d8c7c6b4b7d52c07c7dd8b32d57cd548ed110ad2793c2f419bf22f6ad.png\" alt=\"picture 3\" />  </p>\n<p>Note the status <strong>“Pending”</strong> of the frontend pod. We will revisit that in a later step. </p>\n<h3 id=\"amazonelastickubernetesserviceoverview\">Amazon Elastic Kubernetes Service - Overview</h3>\n<p>AWS makes it easy to run Kubernetes. You can choose to manage Kubernetes infrastructure <strong>yourself with Amazon EC2</strong> or get an <strong>automatically provisioned</strong>, managed Kubernetes control plane with Amazon EKS. Either way, you get powerful, <strong>community-backed integrations</strong> to AWS services like <strong>VPC</strong>, <strong>IAM</strong>, and <strong>service discovery</strong> as well as the <strong>security</strong>, <strong>scalability</strong>, and <strong>high-availability</strong> of AWS.</p>\n<h3 id=\"dynatraceoneksdynatraceoperator\">Dynatrace on EKS - Dynatrace Operator</h3>\n<p>One key Dynatrace advantage is <strong>ease of activation</strong>. OneAgent technology <strong>simplifies deployment</strong> across large enterprises and <strong>relieves engineers</strong> of the burden of instrumenting their applications by hand. </p>\n<p>As Kubernetes adoption continues to grow, it becomes more important than ever to <strong>simplify the activation of observability</strong> across workloads without sacrificing the deployment automation that Kubernetes provides. </p>\n<p>The Dynatrace Operator <strong>automates the deployment</strong> of required Dynatrace components within Kubernetes clusters. Observability should be <strong>as cloud-native as Kubernetes</strong> itself.</p>\n<p>In our workshop, we have already pre-installed the Dynatrace Operator via helm in the initial provisioning script.</p>\n<p><em>Verify</em> Dynatrace Deployment in EKS using <strong>kubectl</strong></p>\n<ol>\n<li><em>Open</em> <strong>CloudShell</strong></li>\n<li>(Optional – as already installed: <em>install</em> <strong>kubectl</strong>)</li>\n<li><em>Run</em> the <strong>following commands</strong>: </li>\n</ol>\n<pre><code class=\"hljs\"> kubectl <span class=\"hljs-builtin-name\">get</span> dynakube -n dynatrace\n</code></pre>\n<pre><code class=\"hljs\"> kubectl <span class=\"hljs-builtin-name\">get</span> pod -n dynatrace\n</code></pre>\n<p><em>Verify</em> that the <strong>DynaKube (Dynatrace Custom Resource) and all pods in the Dynatrace namespace</strong> are ready &amp; running. </p>\n<pre><code class=\"hljs\">[cloudshell<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">user</span><span class=\"hljs-variable\">@ip</span><span class=\"hljs-number\">-10</span><span class=\"hljs-number\">-142</span><span class=\"hljs-number\">-77</span><span class=\"hljs-number\">-211</span> app<span class=\"hljs-operator\">-</span>scripts]$ kubectl <span class=\"hljs-keyword\">get</span> dynakube <span class=\"hljs-operator\">-</span>n dynatrace\nNAME               APIURL                                    STATUS    AGE\nworkshop<span class=\"hljs-operator\">-</span>cluster   https:<span class=\"hljs-operator\">/</span><span class=\"hljs-operator\">/</span>tqp85835.live.dynatrace.com<span class=\"hljs-operator\">/</span>api   <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">55</span>m\n[cloudshell<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">user</span><span class=\"hljs-variable\">@ip</span><span class=\"hljs-number\">-10</span><span class=\"hljs-number\">-142</span><span class=\"hljs-number\">-77</span><span class=\"hljs-number\">-211</span> app<span class=\"hljs-operator\">-</span>scripts]$ kubectl <span class=\"hljs-keyword\">get</span> po <span class=\"hljs-operator\">-</span>n dynatrace\nNAME                                  READY   STATUS    RESTARTS   AGE\ndynatrace<span class=\"hljs-operator\">-</span>oneagent<span class=\"hljs-operator\">-</span>csi<span class=\"hljs-operator\">-</span>driver<span class=\"hljs-number\">-9</span>ttw2   <span class=\"hljs-number\">4</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">4</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\ndynatrace<span class=\"hljs-operator\">-</span>oneagent<span class=\"hljs-operator\">-</span>csi<span class=\"hljs-operator\">-</span>driver<span class=\"hljs-operator\">-</span>bcqcl   <span class=\"hljs-number\">4</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">4</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\ndynatrace<span class=\"hljs-operator\">-</span>operator<span class=\"hljs-number\">-58</span>bd4995bf<span class=\"hljs-operator\">-</span>r2t7b   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\ndynatrace<span class=\"hljs-operator\">-</span>webhook<span class=\"hljs-operator\">-</span>d6f748f58<span class=\"hljs-number\">-5</span>wg2k     <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\nworkshop<span class=\"hljs-operator\">-</span>cluster<span class=\"hljs-operator\">-</span>activegate<span class=\"hljs-number\">-0</span>         <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\nworkshop<span class=\"hljs-operator\">-</span>cluster<span class=\"hljs-operator\">-</span>oneagent<span class=\"hljs-number\">-7</span>q2md       <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\nworkshop<span class=\"hljs-operator\">-</span>cluster<span class=\"hljs-operator\">-</span>oneagent<span class=\"hljs-operator\">-</span>gj6gg       <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">56</span>m\n</code></pre>\n<p><img src=\"assets/4c0082ad0999d5bb98712ba0eda2e47273a956b3e58372f80e9b86ebddf00ea8.png\" alt=\"picture 4\" />  </p>\n<h3 id=\"kubernetesobservabilitywithdynatrace\">Kubernetes Observability with Dynatrace</h3>\n<p><strong>Dynatrace Kubernetes App</strong></p>\n<p><em>Open</em> the <strong>Kubernetes app</strong> in the <strong>Dynatrace platform</strong>. </p>\n<p>You will immediately get a first overview of the <strong>health state</strong> of the most important Kubernetes objects within your K8s clusters. Notice the links to <strong>ready-made</strong> dashboards for various Kubernetes object types (e.g. Node - Pods).</p>\n<p><img src=\"assets/c93c620e2a58be5bc14c48661b31b3537cb7d5e6dcbceaee068317f49588a3cb.png\" alt=\"picture 5\" />  </p>\n<p><strong><em>Optional – Out-of-the-box health alerts</em></strong>\nNote the <strong>info message highlighting</strong> that there are some out-of-the-box alerts are inactive. You can investigate the list of health alerts that are available out of the box by either <em>clicking</em> on <strong>“show”</strong> in this info message or by <em>switching</em> to the <strong>“Recommendations”</strong> tab in the K8s App.</p>\n<p><img src=\"assets/8abd1eef2341fdd9f6c69ad021f79a0fa55a8ddc57b2d2037f6cc8de7f12c956.png\" alt=\"picture 6\" />  </p>\n<p><strong><em>Optional – Deploy Dynatrace in a Kubernetes cluster</em></strong></p>\n<p><em>Open</em> the <strong>Kubernetes App</strong> in your Dynatrace tenant and <em>click</em> on “<strong>Add cluster</strong>” in the <strong>upper right corner</strong>. </p>\n<p>The <strong>Kubernetes App</strong> guides you through <strong>onboarding a new K8s cluster to Dynatrace via helm</strong>. More information about the different deployment options can be found in our <a href=\"https://docs.dynatrace.com/docs/ingest-from/setup-on-k8s\">documentation</a>.</p>\n<p><img src=\"assets/533cbcaa0fa8e83754ce3daa2235958eb8f0baa28bc5c889f07ca6b6c777bf2f.png\" alt=\"picture 7\" />  </p>\n<p>Kubernetes Explorer</p>\n<ul>\n<li><em>Navigate</em> to the <strong>Kubernetes Explorer</strong></li>\n<li><em>Explore</em> the <strong>unhealthy workloads</strong> by directly <em>clicking</em> on the <strong>number of unhealthy workloads</strong> in the <strong>health status</strong> above the cluster table.</li>\n</ul>\n<p><img src=\"assets/90b498b162ec3f8a88e491a2906198c69830ab7a52ff8ba6011ffe4a7c929c0c.png\" alt=\"picture 8\" />  </p>\n<p><img src=\"assets/a1c2d6991374195fb1a2c51fafdd68f074e4ccefa4c9a15672c7e23ccafa9338.png\" alt=\"picture 9\" />  </p>\n<p><em>Analyze</em> the unhealthy workload <strong>“frontend”</strong> in namespace <strong>“orders”</strong>.</p>\n<p>Dynatrace provides all <strong>Observability signals</strong> in context (metrics, logs, events, traces) of this workload and shows you why it is unhealthy.</p>\n<p><img src=\"assets/582c7d803b2910eb4c476549a8a42e9cb434a6704f0d155f36841f4efd920e15.png\" alt=\"picture 10\" />  </p>\n<p><img src=\"assets/0d69502f43f3a97c746776d8a79d689bd71c49c1d96b1c662b952ee939e32935.png\" alt=\"picture 11\" />  </p>\n<p>In this case, the pod can’t be scheduled as there are <strong>not sufficient resources available</strong> on any node.</p>\n<p><img src=\"assets/585d35f6806e321b88fd172e8c318789764b56c375d7ed1e1a30dd8ca8c43ed1.png\" alt=\"picture 12\" />  </p>\n<p>Do you remember the initial EKS setup? Didn’t we have a <strong>node autoscaler</strong> in place? \nAs it turns out, the <strong>maximum Size</strong> of the Autoscaling Group was already reached (2 nodes). Can we prevent such a problem in the future?</p>\n<h3 id=\"k8sawsworkflowswithawsec2apis\">K8s/AWS Workflows with AWS EC2 APIs</h3>\n<p>Knowing what Observability data is available within Dynatrace and how to manipulate it using <strong>DQL</strong> is a great first step. The next step is to understand <strong>how to automate processes</strong> within our organization using that information. Dynatrace allows users to <strong>trigger actions from workflows</strong> and apply <strong>self-healing actions</strong> so you don’t need to wake up SREs or Clouds Ops teams on weekends or during nights. </p>\n<p>We do not have enough time to create another workflow from scratch, so let’s <strong>import a workflow from a Template</strong>. </p>\n<ol>\n<li><em>Open</em> <strong>Workflow App</strong></li>\n<li><em>Select</em> <strong>“Upload”</strong> in the <strong>upper right corner</strong></li>\n<li><em>Select</em> and <em>open</em> the <strong>manage-eks-autoscaling-group-size-workflow.yaml file</strong> in the Github repository</li>\n<li><em>Check</em> the <strong>required apps</strong> and <em>click</em> <strong>“Next”</strong></li>\n</ol>\n<p><img src=\"assets/60864fdaad584194af25e4437de981d18029078855ff857b7dd2eb7eac3b257e.png\" alt=\"picture 13\" />  </p>\n<ol start=\"5\">\n<li><em>Select</em> the AWS connection <strong>“PerformAWSConnect”</strong> created in Lab 2 and Import Workflow</li>\n</ol>\n<p><img src=\"assets/fed1dcb35f26221c1f3e674ee0ed68d588092579aa79652dc3501d8c47ce3dac.png\" alt=\"picture 14\" />  </p>\n<p><em>Analyze</em> <strong>each step</strong> in the workflow and <em>make sure</em> the <strong>Davis Problem Trigger is enabled</strong>.</p>\n<p><img src=\"assets/0b90d1a970e7f2b33cea3c7bfc6a5511ef695b55a4dbbbfc08120a7a7bb611bf.png\" alt=\"picture 15\" />  </p>\n<ul>\n<li><strong>Davis Problem Trigger</strong><ul>\n<li>The workflow gets triggered <strong>when Davis AI detects a reliability problem</strong> in with a pod stuck in pending. For our example, we scoped the workflow action to only trigger this workflow if the problem occurs for the namespace of one of our most important apps called <strong>“orders”</strong>. </li></ul></li>\n<li><strong>Analyze Pending Pods</strong><ul>\n<li>In this initial step, we double-check whether there is a pending pod that is <strong>not already marked for deletion</strong>.  </li></ul></li>\n<li><strong>Fetch node group labels</strong><ul>\n<li>Next, we determine the node group that is <strong>most likely the one that lead to the pending pod</strong> due to <strong>insufficient resource coverage</strong>. For this purpose, we’re analyzing the utilization of the nodes and take the node group including the node with the highest utilization. </li>\n<li><strong><em>Note</em></strong>: We took a shortcut in this example to keep the complexity of the workflow and the amount of instrunctions for this HoT session at a managebel level. To be 100% precise, we’d need to check the <strong>taints</strong> and <strong>tolerations</strong> of the pending pod as well as matching node groups. You can setup &amp; connect DynatraceEdgeConnect for this purpose to retrieve the full yaml from the pod and nodes via Kubernetes API and use it in a workflow action. \n      - Moreoever, we have some <strong>exciting updates</strong> in our roadmap section.</li></ul></li>\n<li><strong>Describe Auto Scaling Group</strong><ul>\n<li>We <em>use</em> the EC2 Action “<strong>Describe auto scaling group</strong>” to get the name of the EC2 autoscaling group based on the <strong>EKS nodegroup name</strong>. This action sends a request to the <strong>AWS EC2 Autoscaling API</strong>.</li></ul></li>\n<li><strong>Analyze Auto Scaling Capacity</strong><ul>\n<li>This action executes <strong>javascript code</strong> where we analyze the <strong>current</strong>, <strong>desired</strong> and <strong>maximum capacity</strong> of the Autoscaling Group. In case the desired capacity is already at the <strong>maximum level</strong>, we <em>increase</em> the <strong>maximum ASG size by 2</strong>. </li>\n<li><strong><em>Note</em></strong>: If you don’t have a cluster autoscaler in place, you can update the desired capacity with this Dynatrace workflow, too. </li></ul></li>\n<li><strong>Upgrade Auto Scaling Group Max Size</strong><ul>\n<li>We <em>use</em> the EC2 Action “<strong>Update auto scaling group</strong>” to send a requeest to the <strong>EC2 autoscaling API</strong> and update the <strong>ASG with the parameters defined</strong> in the previous step. </li></ul></li>\n</ul>\n<p><strong>Workflow Execution</strong></p>\n<p><em>Check</em> whether the workflow has been already <strong>successfully executed</strong>. If not, <em>select</em> <strong>Davis problem trigger</strong>, <em>click</em> on “<strong>query past events</strong>,” and then <em>run</em> the <strong>workflow manually</strong>.</p>\n<p><img src=\"assets/93fab182b507f0fb029a0285283d50ae3f383b5a0716653c6a2fb9a2c6b878ef.png\" alt=\"picture 16\" />  </p>\n<p>Check the number of <strong>Kubernetes nodes</strong> in the Dynatrace <strong>Kubernetes App</strong> (or AWS console). You should now see <strong>3 Kubernetes nodes</strong> and <strong>no longer any pod stuck in pending</strong>!</p>\n<p><strong><em>Note</em></strong>: The workflow has <strong>increased the maximum Size</strong> in the Autoscaling Group from <strong>2 to 4 instances</strong>. It takes quite some time (~10 minutes) until this change is reflected in the EKS node group details displayed in the <strong>AWS Console</strong>. While the <strong>Autoscaling group information is updated ad-hoc</strong>, unfortunately you don’t have sufficient permissions with your workshop participant AWS user to access it.</p>","activityList":[]},{"id":"5","name":"Lab 3 – AWS Infra Logs via Firehose\r","content":"<h2 id=\"lab3awsinfralogsviafirehose\">Lab 3 – AWS Infra Logs via Firehose</h2>\n<h3 id=\"introduction\">Introduction</h3>\n<p>In this lab, we will learn how to integrate <strong>Cloud platform events</strong> with <strong>Dynatrace</strong>. <strong>Platform events</strong> are mostly generated in the form of <strong>logs</strong> when <strong>services</strong> are being instantiated. It's critical that we get these <strong>logs</strong> and <strong>events</strong> into a <strong>centralized platform</strong> so that the ops team can <strong>troubleshoot with ease</strong>. </p>\n<p>For the hands-on part of this lab, we will showcase the integration with <strong>AWS services via CloudWatch</strong> and <strong>Data Firehose</strong>. We will get various <strong>logs from EKS</strong> and at the end of the lab you will be able to see these logs within Dynatrace in near real-time.</p>\n<p>Lab Prerequisites</p>\n<ul>\n<li><em>Access</em> to <strong>AWS account</strong> with the relevant <strong>permissions</strong> to <em>create</em> an <strong>EKS cluster</strong> and <strong>Kinesis Data Firehose</strong></li>\n<li>Able to <em>navigate</em> through <strong>AWS console</strong> with ease</li>\n</ul>\n<h3 id=\"labsteps\">Lab Steps</h3>\n<p>We will follow instructions from <strong>Dynatrace</strong> <strong>documentation</strong> to <em>create</em> the <strong>Firehose Delivery Pipeline</strong>: <a href=\"https://docs.dynatrace.com/docs/ingest-from/amazon-web-services/integrate-with-aws/aws-logs-ingest/lma-stream-logs-with-firehose\">https://docs.dynatrace.com/docs/ingest-from/amazon-web-services/integrate-with-aws/aws-logs-ingest/lma-stream-logs-with-firehose</a></p>\n<p><strong><em>Tip</em></strong>: To successfully <em>execute</em> the request below, you need an <strong>access token</strong> with <code>logs.ingest</code> scope.</p>\n<p>To learn how to <em>create</em> <strong>API</strong> key, see this: <a href=\"https://docs.dynatrace.com/docs/manage/identity-access-management/access-tokens-and-oauth-clients/access-tokens#create-api-token\">https://docs.dynatrace.com/docs/manage/identity-access-management/access-tokens-and-oauth-clients/access-tokens#create-api-token</a></p>\n<p><strong><em>Step 1.</em></strong> <em>Execute</em> the below <strong>commands</strong> while in the <strong>AWS console</strong> (note the **live.dynatrace.com URI, and NO trailing “/”)</p>\n<ul>\n<li><strong>DYNATRACE<em>API</em>URL</strong>=&lt;your_API_URL> <ul>\n<li>(e.g., DYNATRACE<em>API</em>URL=\"https://sur12345.live.dynatrace.com\")</li></ul></li>\n<li><strong>DYNATRACE<em>API</em>KEY</strong>=&lt;your_API_token> <ul>\n<li>(e.g., DYNATRACE<em>API</em>KEY=\"dt0a01.sur12345.1211asdsdfaesdf56…asdfasdfdf\"</li>\n<li><strong><em>Note:</em></strong> This api key is available in your dashboard under ApiTokenDashboard)</li></ul></li>\n<li><strong>STACK_NAME</strong>=dynatrace-log-delivery-stream</li>\n</ul>\n<pre><code class=\"hljs\"><span class=\"hljs-built_in\">wget</span> <span class=\"hljs-literal\">-O</span> dyna<span class=\"hljs-built_in\">trace-firehose</span><span class=\"hljs-literal\">-log</span><span class=\"hljs-literal\">-stream</span>.yaml https://assets.cloud.dynatrace.com/awslogstreaming/dyna<span class=\"hljs-built_in\">trace-firehose</span><span class=\"hljs-literal\">-log</span><span class=\"hljs-literal\">-stream</span>.yaml &amp;&amp; \\\naws cloudformation deploy -<span class=\"hljs-literal\">-capabilities</span> CAPABILITY_NAMED_IAM -<span class=\"hljs-literal\">-template</span><span class=\"hljs-operator\">-file</span> ./dyna<span class=\"hljs-built_in\">trace-firehose</span><span class=\"hljs-literal\">-log</span><span class=\"hljs-literal\">-stream</span>.yaml -<span class=\"hljs-literal\">-stack</span><span class=\"hljs-literal\">-name</span> <span class=\"hljs-variable\">$STACK_NAME</span> -<span class=\"hljs-literal\">-parameter</span><span class=\"hljs-literal\">-overrides</span> DtApiUrl=<span class=\"hljs-variable\">$DYNATRACE_API_URL</span> DtApiToken=<span class=\"hljs-variable\">$DYNATRACE_API_KEY</span>\n</code></pre>\n<p>Sample Output:</p>\n<pre><code class=\"hljs\">CloudWatchSubscriptionFilterRoleArn\n<span class=\"hljs-symbol\">arn:</span><span class=\"hljs-symbol\">aws:</span>iam::<span class=\"hljs-number\">133220408703</span><span class=\"hljs-symbol\">:role/dynatrace-log-delivery-stream-CloudWatchLogsRole-wgg3reyD7A73</span>\nFirehoseArn\n<span class=\"hljs-symbol\">arn:</span><span class=\"hljs-symbol\">aws:</span><span class=\"hljs-symbol\">firehose:</span>ap-northeast<span class=\"hljs-number\">-1</span><span class=\"hljs-symbol\">:</span><span class=\"hljs-number\">133220408703</span><span class=\"hljs-symbol\">:deliverystream/dynatrace-log-delivery-stream</span>     \n</code></pre>\n<p><strong><em>Step 2.</em></strong> Once the <strong>Firehose Stream</strong> is in “<strong>active</strong>” state, <em>test</em> the connection between <strong>AWS</strong> and <strong>Dynatrace</strong> by <em>sending</em> demo data.</p>\n<ul>\n<li><em>Open</em> <strong>Data Firehose</strong> in <strong>Amazon Console</strong>.</li>\n<li><em>Click</em> the “<strong>dynatrace-log-delivery-stream</strong>\" you created</li>\n<li><em>Click</em> “<strong>Test with demo data</strong>”</li>\n</ul>\n<p><img src=\"assets/657ffc968c98eb54f1cb999e2a0e086f0101367b51e73303429cbb7969725e46.png\" alt=\"picture 0\" />  </p>\n<ul>\n<li><em>Inside</em> your <strong>DT tenant</strong>, <em>open</em> <strong>Logs App</strong></li>\n<li><em>Create</em> <strong>logs</strong> filter with the <strong>ARN</strong> for <strong>data firehose</strong></li>\n<li>Use the ARN of your resource to filter the logs</li>\n</ul>\n<p><img src=\"assets/f6665fa51f2140612a34a5e5186d73cc6f93eac893c85d10ff6cc8889e3f9f07.png\" alt=\"picture 1\" />  </p>\n<p><img src=\"assets/0019ab8ac3c910e81b8d9212608fa151531ec4a68edfebaddad1abf566e2d4d9.png\" alt=\"picture 2\" />  </p>\n<p><img src=\"assets/eac288d32f8bedc3773940f922fe3f089160826ee2555b25f59e30595f2c09df.png\" alt=\"picture 3\" />  </p>\n<p><strong><em>Step 3.</em></strong> Now let’s <em>onboard</em> the <strong>logs</strong> from the <strong>EKS cluster</strong> into <strong>Dyntrace</strong>.</p>\n<p>In the <strong>EKS cluster</strong> you <em>created</em> earlier, <em>navigate</em> to the “<strong>Observability</strong>” tab and <em>open</em> “<strong>Manage logging</strong>”</p>\n<p><img src=\"assets/9f988d6a568b622d64cdf74f87e6097a97a6ddf73f401cc034d5d28b7d950d12.png\" alt=\"picture 4\" />  </p>\n<p><em>Select</em> the <strong>sources</strong> you’d like to <strong>log</strong>, and <em>save</em> your <em>changes</em>. In the below screenshot you see that all the <strong>platform-level logs</strong> are <em>selected</em>:</p>\n<p><img src=\"assets/ed5674a2c6fa3ea31af6ef211a057f5f48db0ee0ff4cc78a1a86a19acbcc25ee.png\" alt=\"picture 5\" />  </p>\n<p><strong><em>Step 4.</em></strong> Let’s <em>subscribe</em> to the <strong>log group</strong> where <strong>EKS</strong> <em>sends</em> those <strong>platform logs</strong>.</p>\n<ul>\n<li><em>Open</em> <strong>CloudWatch</strong></li>\n<li><em>Navigate</em> to <strong>Log Groups</strong></li>\n</ul>\n<p><img src=\"assets/5e91d57471ac04f0dbeecc76391ad46d8756480b3c6063890123c180acdaef4f.png\" alt=\"picture 6\" />  </p>\n<p><img src=\"assets/1ccc775b5968647d32ee07ab43ecdbec5ee88e195e4a12da3cc7b4ad117c0d15.png\" alt=\"picture 7\" />  </p>\n<p><img src=\"assets/bc4dc365a08de04d37827267216c593885b793ad5904a25d6be2871dd2780978.png\" alt=\"picture 8\" />  </p>\n<p><em>Execute</em> the below commands on your <strong>AWS Cloud shell</strong>:</p>\n<pre><code class=\"hljs\">wget -O dynatrace-firehose-logs.<span class=\"hljs-keyword\">sh</span> http<span class=\"hljs-variable\">s:</span>//assets.cloud.dynatrace.<span class=\"hljs-keyword\">com</span>/awslogstreaming/dynatrace-firehose-logs.<span class=\"hljs-keyword\">sh</span> &amp;&amp; chmod +<span class=\"hljs-keyword\">x</span> dynatrace-firehose-logs.<span class=\"hljs-keyword\">sh</span>\n</code></pre>\n<pre><code class=\"hljs\">.<span class=\"hljs-regexp\">/dynatrace-firehose-logs.sh subscribe --log-groups /</span>aws<span class=\"hljs-regexp\">/eks/</span>dynatrace-workshop/cluster\n</code></pre>\n<p><img src=\"assets/70daf7167dea9997b366b9d10588006810e2be6e0c3b6b1da7955cfdba902e99.png\" alt=\"picture 9\" /> </p>\n<p>Once you have <em>subscribed</em>, you can see those <strong>logs</strong> within your <strong>Dynatrace tenant</strong>:</p>\n<p><img src=\"assets/89989c8926f143a8b28d2257b8e4a447dd845b55fc45318767b10176a58d6b5e.png\" alt=\"picture 10\" />  </p>\n<h3 id=\"optionalappendixforlab3\">Optional Appendix for Lab 3</h3>\n<p>Use this <strong>guide</strong> in case your <strong>EKS cluster</strong> is not <em>running</em> and you need to <em>create</em> a new one just to complete this <strong>lab</strong>.</p>\n<p><strong><em>Step 1</em></strong>. <em>Open</em> <strong>AWS Cloudshell</strong></p>\n<p><img src=\"assets/1c3eeeee02688d530dfd2ed77d83c64390915f8b859c964c36c05555c954f258.png\" alt=\"picture 0\" />  </p>\n<p><strong><em>Step 2.</em></strong> The <strong>eksctl CLI</strong> is used to work with <strong>EKS clusters</strong>. It automates many individual tasks. </p>\n<p>The below commandline is to <em>install</em> <strong>EKSCTL</strong>. These are taken from: <a href=\"https://eksctl.io/installation/\">https://eksctl.io/installation/</a></p>\n<pre><code class=\"hljs\">ARCH=amd64\nPLATFORM=$(uname -s)_<span class=\"hljs-variable\">$ARCH</span>\ncurl -sLO https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/eksctl-io/</span>eksctl<span class=\"hljs-regexp\">/releases/</span>latest<span class=\"hljs-regexp\">/download/</span>eksctl_<span class=\"hljs-variable\">$PLATFORM</span>.tar.gz\ncurl -sL <span class=\"hljs-string\">&quot;https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt&quot;</span> | grep <span class=\"hljs-variable\">$PLATFORM</span> | sha256sum –check\ntar -xzf eksctl_<span class=\"hljs-variable\">$PLATFORM</span>.tar.gz -C /tmp &amp;&amp; rm eksctl_<span class=\"hljs-variable\">$PLATFORM</span>.tar.gz\nsudo mv <span class=\"hljs-regexp\">/tmp/</span>eksctl <span class=\"hljs-regexp\">/usr/</span>local/bin\n</code></pre>\n<p><strong><em>Step 3.</em></strong> You can now go ahead and <em>create</em> a <strong>cluster using the below command</strong>. Remember to <em>change</em> the <strong>name of the cluster and the region</strong>.</p>\n<pre><code class=\"hljs\"><span class=\"hljs-comment\">eksctl</span> <span class=\"hljs-comment\">create</span> <span class=\"hljs-comment\">cluster</span> --<span class=\"hljs-comment\">name</span> <span class=\"hljs-comment\">suraj</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">hot</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">perform2025</span> --<span class=\"hljs-comment\">region</span> <span class=\"hljs-comment\">ap</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">northeast</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">1</span> --<span class=\"hljs-comment\">fargate</span>\n</code></pre>\n<p><strong><em>Step 4.</em></strong> You should be able to see the progress of the <strong>EKS cluster creation</strong> within <strong>CloudFormation</strong> -&gt; <strong>Stacks</strong>.</p>\n<p><img src=\"assets/fb2aada6e9380609086c0d50b6b08a65242228ba27fd25027db0669569370dc8.png\" alt=\"picture 1\" />  </p>\n<p><strong><em>Step 5.</em></strong> <em>Clean up</em> <strong>EKS</strong></p>\n<pre><code class=\"hljs\">eksctl <span class=\"hljs-keyword\">delete</span> <span class=\"hljs-keyword\">cluster</span> <span class=\"hljs-comment\">--name suraj-hot-perform2025 --region ap-northeast-1</span>\n</code></pre>","activityList":[]}]